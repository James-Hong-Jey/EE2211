{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Left / Right Inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo-inverse of X:\n",
      "[[ 0.78723404 -0.10638298]\n",
      " [-0.10638298  0.01823708]]\n",
      "\n",
      "Least squares solution w:\n",
      "[[ 0.74468085]\n",
      " [-0.12765957]]\n",
      "Now the output is:\n",
      "[[-0.0212766]]\n"
     ]
    }
   ],
   "source": [
    "# Left / Right Inverse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Please replace \"MatricNumber\" with your actual matric number here and in the filename\n",
    "def A1_MATRICNUMBER(X, y):\n",
    "    # your code goes here\n",
    "    # (Xt * X)\n",
    "    InvXTX = np.linalg.inv(X.T @ X) \n",
    "\n",
    "    wLeft = InvXTX @ X.T @ y\n",
    "    # wRight = X.T @ np.linalg.inv(X @ X.T) @ y\n",
    "\n",
    "    # return in this order\n",
    "    return InvXTX, wLeft\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    # X = np.array([[1, 1, 2],\n",
    "    #             [1, 0, 6],\n",
    "    #             [1, 1, 0],\n",
    "    #             [1, 0, 5],\n",
    "    #             [1, 1, 7]])\n",
    "\n",
    "    X = np.array([[1, 4],\n",
    "                [1, 7],\n",
    "                [1, 10],\n",
    "                [1, 2],\n",
    "                [1, 3],\n",
    "                [1, 9]])\n",
    "\n",
    "    y = np.array([[-1],\n",
    "                [-1],\n",
    "                [-1],\n",
    "                [1],\n",
    "                [1],\n",
    "                [1]])\n",
    "\n",
    "    X_pseudo_inv, w = A1_MATRICNUMBER(X, y)\n",
    "\n",
    "    print(\"Pseudo-inverse of X:\")\n",
    "    print(X_pseudo_inv)\n",
    "    print(\"\\nLeast squares solution w:\")\n",
    "    print(w)\n",
    "\n",
    "    xTest = np.array([[1, 6]])\n",
    "    print(\"Now the output is:\")\n",
    "    print(xTest @ w)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  [[  1.   1.   3.   4.   1.   3.   4.   9.  12.  16.   1.   3.   4.   9.\n",
      "   12.  16.  27.  36.  48.  64.]\n",
      " [  1.   6.  -1.   6.  36.  -6.  36.   1.  -6.  36. 216. -36. 216.   6.\n",
      "  -36. 216.  -1.   6. -36. 216.]\n",
      " [  1.   5.   3.   3.  25.  15.  15.   9.   9.   9. 125.  75.  75.  45.\n",
      "   45.  45.  27.  27.  27.  27.]\n",
      " [  1.   2.   1.   2.   4.   2.   4.   1.   2.   4.   8.   4.   8.   2.\n",
      "    4.   8.   1.   2.   4.   8.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m P \u001b[38;5;241m=\u001b[39m poly\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP: \u001b[39m\u001b[38;5;124m\"\u001b[39m, P)\n\u001b[1;32m---> 13\u001b[0m w_poly \u001b[38;5;241m=\u001b[39m \u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw_poly: \u001b[39m\u001b[38;5;124m\"\u001b[39m, w_poly)\n\u001b[0;32m     16\u001b[0m xTest \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m6\u001b[39m]])\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "# Adapted from A2 - Single polynomial thingy\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "\n",
    "order = 3\n",
    "\n",
    "X = np.array([[1, 3, 4], [6, -1, 6], [5, 3, 3], [2, 1, 2]])\n",
    "poly = PolynomialFeatures(order)\n",
    "P = poly.fit_transform(X)\n",
    "print(\"P: \", P)\n",
    "w_poly = inv(P.T @ P) @ P.T @ y\n",
    "print(\"w_poly: \", w_poly)\n",
    "\n",
    "xTest = np.array([[6]])\n",
    "pTest = poly.fit_transform(xTest)\n",
    "predict_yp = pTest @ w_poly\n",
    "print(\"Predicted yp: \", predict_yp)\n",
    "\n",
    "yp_class_predict = [[1 if x >=0 else -1 ] for x in predict_yp ]\n",
    "print(\"Predicted yp class: \", yp_class_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr between x1 and y: 0.3543136694270562\n",
      "Corr between x2 and y: 0.7542316187956285\n",
      "Corr between x3 and y: -0.13588590067035158\n",
      "Corr between x4 and y: 0.0871718827743873\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training = np.array([[-0.709, 1.7255, 0.9539, -0.7581, -1.035, -1.049],\n",
    "                     [2.8719, 1.5014, 1.8365, -0.5467, 1.8274, 0.3501],\n",
    "                     [-1.8349, 0.4055, 1.0118, 0.5171, 0.7279, 1.2654],\n",
    "                     [2.6354, 2.7448, 1.4616, 0.7258, -1.6893, -1.7512], \n",
    "                     [0.8206, 1.0639, 0.6895, -0.0252, 0.995, 0.6608]\n",
    "                     ])\n",
    "\n",
    "corr_x1_y = np.corrcoef(training[0], training[4])[0, 1]\n",
    "corr_x2_y = np.corrcoef(training[1], training[4])[0, 1]\n",
    "corr_x3_y = np.corrcoef(training[2], training[4])[0, 1]\n",
    "corr_x4_y = np.corrcoef(training[3], training[4])[0, 1]\n",
    "\n",
    "print(f'Corr between x1 and y: {corr_x1_y}')\n",
    "print(f'Corr between x2 and y: {corr_x2_y}')\n",
    "print(f'Corr between x3 and y: {corr_x3_y}')\n",
    "print(f'Corr between x4 and y: {corr_x4_y}')\n",
    "# Look at the highest ABSOLUTE correlation i.e. -0.999 > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w at iteration  0  is  3.0279415498198925\n",
      "w at iteration  1  is  3.0504765445441904\n",
      "w at iteration  2  is  3.068599072469998\n",
      "w at iteration  3  is  3.083145988671483\n",
      "w at iteration  4  is  3.0948087192303437\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "learning_rate = 0.1\n",
    "n = 5\n",
    "w = 3 # Initialisation\n",
    "cost_function = math.sin(w) ** 2\n",
    "def gradient(w):\n",
    "    return 2 * math.sin(w) * math.cos(w) \n",
    "    # Manually derive this\n",
    "\n",
    "for i in range(n):\n",
    "    w -= learning_rate * gradient(w)\n",
    "    print(\"w at iteration \", i, \" is \", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x at iteration  0  is  2.36\n",
      "y at iteration  0  is  2.8200000000000003\n",
      "z at iteration  0  is  -3.36\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "learning_rate = 0.03\n",
    "n = 1\n",
    "x = 2 # Initialisation\n",
    "y = 6\n",
    "z = -3\n",
    "cost_function = x ** 2 * y + y ** 3 + x*y*z\n",
    "def gradient_x(x, y, z):\n",
    "    return 2 * x * y + x * y * z\n",
    "\n",
    "def gradient_y(x, y, z):\n",
    "    return x ** 2 + 3 * y ** 2 + x * z\n",
    "\n",
    "def gradient_z(x, y, z):\n",
    "    return x * y\n",
    "\n",
    "for i in range(n):\n",
    "    x -= learning_rate * gradient_x(x, 6, -3)\n",
    "    print(\"x at iteration \", i, \" is \", x)\n",
    "\n",
    "for i in range(n):\n",
    "    y -= learning_rate * gradient_y(2, y, -3)\n",
    "    print(\"y at iteration \", i, \" is \", y)\n",
    "\n",
    "for i in range(n):\n",
    "    z -= learning_rate * gradient_z(2, 6, z)\n",
    "    print(\"z at iteration \", i, \" is \", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tree and MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following dataset comprising 10 datapoints: \n",
    "\n",
    "{x, y} = {0.2, 2.1}, {0.7, 1.5}, {1.8, 5.8}, {2.2, 6.1}, {3.7, 9.1}, {4.1, 9.5}, {4.5, 9.8}, {5.1, 12.7}, {6.3, 13.8}, {7.4, 15.9}. \n",
    "\n",
    "Our goal is to use a regression tree to predict y from x. Suppose at depth\n",
    "1, we consider a decision threshold of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE at the root: 20.638\n",
      "Overall MSE at depth 1: 5.565\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the dataset\n",
    "data = np.array([[0.2, 2.1],\n",
    "                 [0.7, 1.5],\n",
    "                 [1.8, 5.8],\n",
    "                 [2.2, 6.1],\n",
    "                 [3.7, 9.1],\n",
    "                 [4.1, 9.5],\n",
    "                 [4.5, 9.8],\n",
    "                 [5.1, 12.7],\n",
    "                 [6.3, 13.8],\n",
    "                 [7.4, 15.9]])\n",
    "\n",
    "# Decision threshold\n",
    "threshold = 3\n",
    "\n",
    "# Calculate MSE at the root\n",
    "y_mean = np.mean(data[:, 1])\n",
    "root_mse = np.mean((data[:, 1] - y_mean)**2)\n",
    "\n",
    "# Split the data based on the decision threshold\n",
    "left_data = data[data[:, 0] < threshold]\n",
    "right_data = data[data[:, 0] >= threshold]\n",
    "\n",
    "# Calculate MSE for left and right groups\n",
    "left_mse = np.mean((left_data[:, 1] - np.mean(left_data[:, 1]))**2)\n",
    "right_mse = np.mean((right_data[:, 1] - np.mean(right_data[:, 1]))**2)\n",
    "\n",
    "# Compute overall MSE at depth 1\n",
    "overall_mse = (left_mse * len(left_data) + right_mse * len(right_data)) / len(data)\n",
    "\n",
    "print(\"MSE at the root:\", round(root_mse, 3))\n",
    "print(\"Overall MSE at depth 1:\", round(overall_mse, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "\n",
    "# Please replace \"MatricNumber\" with your actual matric number here and in the filename\n",
    "def A2_MATRICNUMBER(N):\n",
    "\n",
    "    iris = load_iris()\n",
    "    X = iris['data']\n",
    "    y = iris['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state = N) # 0.7 is test data 0.3 is training/ Right Inverse\n",
    "\n",
    "    one_hot_encoder = OneHotEncoder(sparse_output=False) # False means array\n",
    "    reshaped_ytr = y_train.reshape(len(y_train), 1) # turn it into a column\n",
    "    Ytr = one_hot_encoder.fit_transform(reshaped_ytr)  \n",
    "\n",
    "    # Do the same for the y_test data\n",
    "    reshaped_yts = y_test.reshape(len(y_test), 1)\n",
    "    Yts = one_hot_encoder.fit_transform(reshaped_yts)\n",
    "\n",
    "    reg_factor = 0.0001\n",
    "    Ptrain_list, Ptest_list, w_list, error_train, error_test= [], [], [], [], []\n",
    "\n",
    "    for order in range (8):\n",
    "        poly = PolynomialFeatures(degree= (order + 1) )\n",
    "        P = poly.fit_transform(X_train)\n",
    "        Pt = poly.fit_transform(X_test)\n",
    "\n",
    "        Ptrain_list.append(P)\n",
    "        Ptest_list.append(Pt)\n",
    "\n",
    "        #Check for over/ underdetermined\n",
    "        #Use the appropriate psuedo inverse (left/right)\n",
    "        samples = P.shape[0]\n",
    "        unknowns = P.shape[1]\n",
    "        if samples > unknowns: # Left inverse - overdetermined\n",
    "            reg_L = reg_factor * np.identity(unknowns)\n",
    "            wp = inv(P.T @ P + reg_L) @ P.T @ Ytr # Primal Ridge\n",
    "        else: # Right inverse - underdetermined\n",
    "            reg_L2 = reg_factor * np.identity(samples)\n",
    "            wp = P.T @ inv(P @ P.T + reg_L2) @ Ytr # Dual Ridge\n",
    "\n",
    "        w_list.append(wp)\n",
    "\n",
    "    # Get errors\n",
    "    for order in range (8):\n",
    "        wp = w_list[order]\n",
    "\n",
    "        # Training\n",
    "        ytr_est_p = Ptrain_list[order] @ wp\n",
    "        ytr_cls_p = [ [1 if y == max(x) else 0 for y in x] for x in ytr_est_p]\n",
    "\n",
    "        ytr1 = np.matrix(Ytr)\n",
    "        ytr2 = np.matrix(ytr_cls_p)\n",
    "        difference_train = np.abs(ytr1 - ytr2)\n",
    "\n",
    "        correct_p_train = np.where(~difference_train.any(axis=1))[0]\n",
    "        incorrect_p_train = len(difference_train) - len(correct_p_train)\n",
    "        error_train.append(incorrect_p_train)\n",
    "\n",
    "        # Testing\n",
    "        yt_est_p = Ptest_list[order] @ wp\n",
    "        yt_cls_p = [ [1 if y == max(x) else 0 for y in x] for x in yt_est_p]\n",
    "\n",
    "        yts1 = np.matrix(Yts)\n",
    "        yts2 = np.matrix(yt_cls_p)\n",
    "        difference_test = np.abs(yts1 - yts2)\n",
    "\n",
    "        correct_p_test = np.where(~difference_test.any(axis=1))[0]\n",
    "        incorrect_p_test = len(difference_test) - len(correct_p_test)\n",
    "        error_test.append(incorrect_p_test)\n",
    "    \n",
    "\n",
    "    error_train_array = np.array(error_train)\n",
    "    error_test_array = np.array(error_test)\n",
    "    # return in this order\n",
    "    return X_train, y_train, X_test, y_test, Ytr, Yts, Ptrain_list, Ptest_list, w_list, error_train_array, error_test_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_out: [-3.75000000e+00  1.73437500e+01 -2.06949554e+03  3.54530191e+09\n",
      " -1.78245948e+28], \n",
      "f1_out: [1.97753906e+002 9.04840475e+004 1.83424770e+013 1.57983925e+038\n",
      " 1.00943571e+113], \n",
      "b_out: [0.50679609 0.4219224  0.34720201 0.28320925 0.22954792], \n",
      "f2_out: [0.23559234 0.16770255 0.11578239 0.07808587 0.05177323], \n",
      "c_out: [-6.00000000e+000 -6.54000000e+002 -9.14704890e+010 -3.50020924e+043\n",
      " -7.50491942e+173], \n",
      "d_out: [3.80632124 5.41623774 4.34358445 5.83403454 3.2746487 ], \n",
      "f3_out: [-7.78493691e+003 -1.19643399e+014 -6.40331702e+054 -5.25375766e+217\n",
      "             -inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_1416\\4146952937.py:57: RuntimeWarning: overflow encountered in scalar power\n",
      "  f3_out[i] = (c_out[i]**5) + (d_out[i]**2 * np.sin(d_out[i]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Please replace \"StudentMatriculationNumber\" with your actual matric number here and in the filename\n",
    "def A3_MATRICNUMBER(learning_rate, num_iters):\n",
    "    # your code goes here\n",
    "\n",
    "    # Part a\n",
    "    a_out = np.zeros(num_iters)\n",
    "    f1_out = np.zeros(num_iters)\n",
    "    a = 2.5 # Initialisation\n",
    "    a_out[0] = a - (learning_rate * 4 * a**3)\n",
    "    f1_out[0] = a_out[0]**4\n",
    "\n",
    "    # Part b\n",
    "    b_out = np.zeros(num_iters)\n",
    "    f2_out = np.zeros(num_iters)\n",
    "    b = 0.6 # Initialisation - Radians\n",
    "    b_out[0] = b - (learning_rate * 2*np.sin(b)*np.cos(b))\n",
    "    f2_out[0] = np.sin(b_out[0]) ** 2\n",
    "\n",
    "    # Part c\n",
    "    c_out = np.zeros(num_iters)\n",
    "    d_out = np.zeros(num_iters)\n",
    "    f3_out = np.zeros(num_iters)\n",
    "    c, d = 2, 3\n",
    "    c_out[0] = c - (learning_rate * (5 * c**4))\n",
    "    d_out[0] = d - (learning_rate * (2 * d * np.sin(d) + d**2 * np.cos(d)))\n",
    "    f3_out[0] = (c_out[0]**5) + (d_out[0]**2 * np.sin(d_out[0]))\n",
    "\n",
    "    for i in range(1, num_iters):\n",
    "        aVal = a_out[i-1]\n",
    "        a_out[i] = aVal - (learning_rate * 4 * aVal**3)\n",
    "        f1_out[i] = a_out[i]**4\n",
    "\n",
    "        bVal = b_out[i-1]\n",
    "        b_out[i] = bVal - (learning_rate * 2*np.sin(bVal)*np.cos(bVal))\n",
    "        f2_out[i] = np.sin(b_out[i]) ** 2\n",
    "\n",
    "        cVal = c_out[i-1]\n",
    "        dVal = d_out[i-1]\n",
    "        c_out[i] = cVal - (learning_rate * (5 * cVal**4))\n",
    "        d_out[i] = dVal - (learning_rate * (2 * dVal * np.sin(dVal) + dVal**2 * np.cos(dVal)))\n",
    "        f3_out[i] = (c_out[i]**5) + (d_out[i]**2 * np.sin(d_out[i]))\n",
    "\n",
    "    # return in this order\n",
    "    return a_out, f1_out, b_out, f2_out, c_out, d_out, f3_out \n",
    "\n",
    "# TESTING\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_iters = 5\n",
    "a_out, f1_out, b_out, f2_out, c_out, d_out, f3_out = A3_MATRICNUMBER(learning_rate, num_iters)\n",
    "print(f\"a_out: {a_out}, \\nf1_out: {f1_out}, \\nb_out: {b_out}, \\nf2_out: {f2_out}, \\nc_out: {c_out}, \\nd_out: {d_out}, \\nf3_out: {f3_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "[[-0.01005025 -6.03015075  7.04020101]\n",
      " [-0.24874372 -1.74623116  1.99497487]\n",
      " [ 0.44723618  3.34170854 -3.78894472]\n",
      " [ 0.03015075  1.09045226 -1.12060302]]\n",
      "[ -1.03266332 -10.09798995  12.13065327]\n"
     ]
    }
   ],
   "source": [
    "# Classifier\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder=OneHotEncoder(sparse_output=False)\n",
    "X = np.array([[1, 3, -2], [-4, 0, -1], [3, 1, 8], [2, 1, 6], [8, 4, 6]])\n",
    "y = np.array([1, 1, 2, 3, 3])\n",
    "# Now add offset to X:\n",
    "X1 = np.array([[1, 1, 3, -2], \n",
    "               [1, -4, 0, -1], \n",
    "               [1, 3, 1, 8], \n",
    "               [1, 2, 1, 6], \n",
    "               [1, 8, 4, 6]])\n",
    "reshaped = y.reshape(len(y), 1) # Reshape Y into a column \n",
    "Y_onehot = onehot_encoder.fit_transform(reshaped)\n",
    "#print(det(X.T@X))\n",
    "#print(det(X@X.T))\n",
    "print(Y_onehot)\n",
    "left_inv = inv(X1.T @ X1) @ (X1.T)\n",
    "#right_inv = X.T @ inv(X @ X.T)\n",
    "#print(right_inv)\n",
    "w = left_inv @ Y_onehot\n",
    "print(w)\n",
    "Xnew1 = np.array([1, 1, -2, 4])\n",
    "Ynew = Xnew1@w\n",
    "print(Ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.74468085 -0.12765957]\n",
      "[ 0.23404255 -0.14893617 -0.53191489  0.4893617   0.36170213 -0.40425532]\n",
      "[[1], [-1], [-1], [1], [1], [-1]]\n",
      "[-0.0212766]\n",
      "poly2\n",
      "[ 2.66875    -0.98359375  0.07109375]\n",
      "[-0.128125  -0.7328125 -0.0578125  0.9859375  0.3578125 -0.425    ]\n",
      "[[-1], [-1], [-1], [1], [1], [-1]]\n",
      "poly4\n",
      "[-11.21971831  13.52136821  -4.88054326   0.65537223  -0.02923541]\n",
      "[-0.76338028 -1.11830986 -1.04225352  1.07605634  0.74647887  1.10140845]\n",
      "[[-1], [-1], [-1], [1], [1], [1]]\n",
      "[[1.000e+00 6.000e+00 3.600e+01 2.160e+02 1.296e+03]]\n",
      "[-2.11975855]\n"
     ]
    }
   ],
   "source": [
    "#code\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# linear regression\n",
    "m_list = [[1, 4], [1, 7], [1, 10], [1, 2], [1, 3], [1, 9]]\n",
    "X = np.array(m_list)\n",
    "leftinv_X = np.linalg.inv(X.T @ X) @ X.T\n",
    "y = np.array([-1, -1, -1, 1, 1, 1])\n",
    "w = leftinv_X.dot(y)\n",
    "print(w)\n",
    "predict_y = X@w\n",
    "print(predict_y)\n",
    "y_class_predict = [[1 if x >=0 else -1 ] for x in predict_y ]\n",
    "print(y_class_predict)\n",
    "Xnew = [[1, 6]]\n",
    "Ynew = Xnew@w\n",
    "print(Ynew)\n",
    "## polynomial regression\n",
    "print('poly2')\n",
    "\n",
    "## Quadratic 2nd order poly\n",
    "order = 2\n",
    "origX= np.array([[4],[7], [10], [2], [3], [9]])\n",
    "poly = PolynomialFeatures(order)\n",
    "P = poly.fit_transform(origX)\n",
    "w_poly = inv(P.T @ P) @ P.T @ y\n",
    "print(w_poly)\n",
    "predict_yp=P@w_poly\n",
    "print(predict_yp)\n",
    "yp_class_predict = [[1 if x >=0 else -1 ] for x in predict_yp ]\n",
    "print(yp_class_predict)\n",
    "\n",
    "## Order 4 poly: overdetermined\n",
    "print('poly4')\n",
    "order = 4\n",
    "poly = PolynomialFeatures(order)\n",
    "P = poly.fit_transform(origX)\n",
    "w_poly = inv(P.T @ P) @P.T @ y\n",
    "print(w_poly)\n",
    "predict_yt=P@w_poly\n",
    "print(predict_yt)\n",
    "yt_class_predict = [[1 if x >=0 else -1 ] for x in predict_yt ]\n",
    "print(yt_class_predict)\n",
    "Xnew = [[1, 1]]\n",
    "Pnew =poly.fit_transform([[6]])\n",
    "print(Pnew)\n",
    "Ynew_poly = Pnew@w_poly\n",
    "print(Ynew_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See matlab code below.\n",
    "function RegressionTreeExam\n",
    "rng(2);\n",
    "x = [0.2 0.7 1.8 2.2 3.7 4.1 4.5 5.1 6.3 7.4];\n",
    "y = x*2 + round(rand(1,length(x))*40)/10;\n",
    "threshold = 3;\n",
    "disp([x; y])\n",
    "disp(['threshold = ' num2str(threshold)]);\n",
    "disp(' ');\n",
    "EE2211 - Introduction to Machine Learning/ Page 18\n",
    "% root\n",
    "root_mse = mean((y - mean(y)).^2);\n",
    "disp(['root mse = ' num2str(root_mse)]);\n",
    "% left x < threshold\n",
    "yL = y(x < threshold);\n",
    "numL = length(yL);\n",
    "mse_L = mean((yL - mean(yL)).^2);\n",
    "disp(['(x < threshold) mse = ' num2str(mse_L)]);\n",
    "% right x > threshold\n",
    "yR = y(x > threshold);\n",
    "numR = length(yR);\n",
    "mse_R = mean((yR - mean(yR)).^2);\n",
    "disp(['(x > threshold) mse = ' num2str(mse_R)]);\n",
    "% Overall MSE\n",
    "overall_MSE = (mse_L * numL + mse_R * numR)/length(y);\n",
    "disp(['overall mse = ' num2str(overall_MSE)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatgpt translation of the above into python: (I dont understand it)\n",
    "import numpy as np\n",
    "\n",
    "def RegressionTreeExam():\n",
    "    np.random.seed(2)\n",
    "    x = np.array([0.2, 0.7, 1.8, 2.2, 3.7, 4.1, 4.5, 5.1, 6.3, 7.4])\n",
    "    y = x * 2 + np.round(np.random.rand(len(x)) * 40) / 10\n",
    "    threshold = 3\n",
    "    \n",
    "    print(\"x:\", x)\n",
    "    print(\"y:\", y)\n",
    "    print(\"threshold =\", threshold)\n",
    "    print()\n",
    "\n",
    "    # root\n",
    "    root_mse = np.mean((y - np.mean(y)) ** 2)\n",
    "    print(\"root mse =\", root_mse)\n",
    "\n",
    "    # left x < threshold\n",
    "    yL = y[x < threshold]\n",
    "    numL = len(yL)\n",
    "    mse_L = np.mean((yL - np.mean(yL)) ** 2)\n",
    "    print(\"(x < threshold) mse =\", mse_L)\n",
    "\n",
    "    # right x > threshold\n",
    "    yR = y[x > threshold]\n",
    "    numR = len(yR)\n",
    "    mse_R = np.mean((yR - np.mean(yR)) ** 2)\n",
    "    print(\"(x > threshold) mse =\", mse_R)\n",
    "\n",
    "    # Overall MSE\n",
    "    overall_MSE = (mse_L * numL + mse_R * numR) / len(y)\n",
    "    print(\"overall mse =\", overall_MSE)\n",
    "\n",
    "RegressionTreeExam()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
